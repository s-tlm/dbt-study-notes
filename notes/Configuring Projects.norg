* Configuring DBT Projects
  Project-wide configuration is declared inside the `dbt_project.yml` file.
  Here we can define the directories of assets and other configs.

** Basic Configuration Structure
   @table
   YAML Key            | Description
   -
   name                | The project name in snake_case
   -
   version             | Version of the project
   -
   require-dbt-version | Restrict the project to work with a range of DBT Core
   versions
   -
   profile             | The profile DBT uses to connect to the data platform
   -
   model-paths         | Directories where models and source files are stored
   -
   seed-paths          | Directories where seed source files are stored
   -
   test-paths          | Directories where test source files are stored
   -
   analysis-paths      | Directories where SQL files used for analyses are
   stored
   -
   macro-paths         | Directories where macros are stored
   -
   snapshot-paths      | Directories where snapshot source files are stored
   -
   docs-paths          | Directories where Markdown doc blocks are stored
   -
   clean-paths         | List of directories to be removed when running dbt
   clean. They should only contain DBT artifacts. By default, DBT will clean
   files in the target-path
   -
   target-path         | Custom directory to store compiled files when running
   dbt test, dbt run or dbt compile. By default, DBT uses the `target` directory
   -
   asset-paths         | Directories that are copied to the `target` directory
   when running dbt docs generate. Useful for things such as images for docs.
   By default, no files are copied
   -
   vars                | Project variables that can be used by the project
   @end

** Configuring Variables
   {:Project Variables:}[More on variables].  

   DBT project variables can be configured in two ways:
   ~ In `dbt_project.yml`
   ~ Through the command-line

*** Defining in `dbt_project.yml`
    Suitable for variables *that rarely change*.
    Use the `vars` config and specify the value and scope.

    @code yaml
    ---
    name: my_dbt_project
    version: 1.0.0

    config-version: 2

    vars:
      # The `start_date` variable will be accessible in all resources
      start_date: '2016-06-01'

      # The `platforms` variable is only accessible to resources in the my_dbt_project project
      my_dbt_project:
        platforms: ['web', 'mobile']

      # The `app_ids` variable is only accessible to resources in the snowplow package
      snowplow:
        app_ids: ['marketing', 'app', 'landing-page']

    models:
    ...
    @end

*** Defining in the Command-Line
    Suitable for variables that can *change frequently*. 
    Use the `--var` argument to define or override variables.
    Accepts a `YAML` dictionary string as input.

    @code sh
    # Valid
    $ dbt run --vars '{"key": "value"}'

    # Also valid
    $ dbt run --vars '{key: value}'

    # Single variables don't need curlys
    $ dbt run --vars 'key: value'
    @end

** On Run-Start & On Run-End
   @code yaml
   ---
   # dbt_project.yml
   on-run-start: sql-statement | [sql-statement]
   on-run-end: sql-statement | [sql-statement]
   @end

   Specify a single or list of SQL statements to be executed before or after:
   - `dbt run`
   - `dbt test`
   - `dbt seed`
   - `dbt snapshot`
   - `dbt build`
   - `dbt compile`
   - `dbt docs generate`

   These hooks can also be used to call macros that return SQL statements.

** Quoting
    @code yaml
    ---
    # dbt_project.yml
    quoting:
      database: true | false
      schema: true | false
      identifier: true | false
      project: true | false
    @end
  
   DBT will quote the following identifiers when creating tables/views or
   resolving `ref` functions:
    - Database
    - Schema
    - Identifier
  
      For most adapters, quoting is set to `true` by default.
      *For Snowflake, quoting is set to `false`.* In Snowflake, all unquoted
      identifiers use UPPER CASE. Therefore, if a model is quoted
      in lower-case, then they can not be selected without using quotes.

      *For Snowflake, its recommended to leave quoting OFF!*

** Dispatch
   {:Multiple Dispatch:}[Notes on multiple dispatch].

   DBT uses {https://en.wikipedia.org/wiki/Multiple_dispatch}[multiple dispatch] to execute code correctly based on the data 
   platform. We can override the default search locations for macros in certain
   namespaces.
  
   By default, DBT will look inside the `root` project and then look for
   implementations in the package named by `macro_namespace`.

*** Example
    Say we implemented a custom macro from `dbt_utils` in the `root` project and 
    want our version to take precedence. If a custom implementation isn't
    available, we want DBT to fallback on the default implementation.

    @code yaml
    ---
    # This is default behaviour
    dispatch:
      - macro_namespace: dbt_utils
        search_order: ['my_root_project', 'dbt_utils']
    @end

** Query Comments
   Allows you to inject a string as a comment in each query that runs in the 
   data platform.

   @table
   Configuration | Definition
   -
   comment       | Optional. The string to be injected as a comment
   -
   append        | Optional, default=false. Whether comment is appended at the
   bottom or placed at the top
   -
   job-label     | BigQuery only
   @end

   @code yaml
   ---
   query-comment:
     comment: string
     append: true | false
     job-label: true | false # BigQuery only!
   @end

   By default, DBT will inject a JSON comment to all queries, containing:
   - dbt version
   - profile name
   - target name
   - node id

   @code sql
   /* {"app": "dbt", "dbt_version": "0.15.0rc2", "profile_name": "debug",
   "target_name": "dev", "node_id": "model.dbt2.my_model"} */
   ...
   @end
